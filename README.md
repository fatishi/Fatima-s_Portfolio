# Fatima Nurmakhamadova - Data Analyst Portfolio 

Hello! I am Fatima, and welcome to my portfolio! üöÄ

## About Me üôãüèª‚Äç‚ôÄÔ∏è
Experienced Data Analyst | Proficient in Python, R, SQL, Power BI, and Tableau | Expertise in Advanced Data Analysis, Predictive Modeling, and Big Data Analytics |

üîç Collaborated with the Head of Data Analytics at Free Float Media, contributing to automated algorithm development quantifying board members' influence at global companies.

üìä Analyzed 1 billion+ records for market basket analysis, driving strategic sales insights.

üí° Master's in Analytics from Northeastern University, GPA: 3.97/4.00.

üåê Multilingual - Fluent in Russian, and Kyrgyz; Proficient in English, Arabic, and Turkish.

## PROJECTS 
## [Capstone Project: Predicting the Aftermath of Fraud on Board of Directors in the US (2017-2022)](https://github.com/fatishi/Fatima-s_Portfolio/tree/main/Capstone%20Project)

- **Code file (my part):** [`Python_Capstone_Fatima`](https://github.com/fatishi/Fatima-s_Portfolio/tree/main/Capstone%20Project/Python_Capstone_Fatima)
- **EDA Dashboards (my part):** [`EDA_PowerBI_Capstone_FatimaN.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Capstone%20Project/EDA_PowerBI_Capstone_FatimaN.pdf)
- **Presentation Slides (group):** [`PPT_Capstone_Group7.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Capstone%20Project/PPT_Capstone_Group7.pdf)
- **Project Report (group):** [`Report_Capstone_Group7.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Capstone%20Project/Report_Capstone_Group7.pdf)

> **DESCRIPTION:**

A final capstone project sponsored by Free Float Media is an Empirical Study on Board Directors in US Companies (2017-2022) that I did with my teammates based on more than 10 data sets provided. The project goal is to analyze the structural aftermath of the director boards during their firms‚Äô disclosed controversial events by predicting their likelihood of departure and finding the factors affecting it. The report covers various aspects of our research such as literature reviews, research methodologies and hypotheses, data analysis, modeling, and so on. The main question we intended to answer in this analysis is:

> **Q:** *"How each characteristic of the individual director influences the departure when their companies involve controversial events?"*

**What I did?**
* Implemented the warehousing for 10 data sources & Created visualization dashboards on Power BI for Exploratory Data Analysis.
* Used Python for data cleaning/engineering and Generated 6 features on the directors' level (individual characteristics).
* Applied machine learning models (Logistic Regression, Decision Tree, etc.) to predict the departure probability (accuracy:85%).
* Implemented Automated machine learning process using Python PyCaret library for the best model among 14 possible.

> **SKILLS:** 

Hypotheses Testing, EDA, Data Cleaning, Data Transformation, Feature Engineering, Descriptive Analysis, Visualization, Writing Functions, Predictive Modeling, Classification  

> **TECHNOLOGY:**

**Power BI, Excel, Python**: Pandas, Numpy, Matplotlib, Seaborn, Sklearn, Statsmodels, Pycaret

![](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Capstone%20Project/images/Pycaret_Capstone.jpg)

## [XN Project: Analysis & Visualization of the Equipment Utilization Using PowerBI](https://github.com/fatishi/Fatima-s_Portfolio/tree/main/XN%20Project)

- **Dashboards & Presentation (group):** [`EDA_PowerBI_Capstone_FatimaN.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/XN%20Project/XN%20Project_PPT_Group10.pdf)

> **DESCRIPTION:**

The experiential learning project sponsored by Simplex Solution is about creating dashboards to be integrated into the construction work management software for large contractors working for gas & electric utilities. This is a group project where I with my teammate (Xiaolu Shen) created dashboard reports and a set of drill-downs to help track and analyze equipment utilization. Most of the equipment is rented, while others are owned. The rent payment depends not on the time the equipment is being turned on (utilization time) but on the total working hours of the crew (billing hours). Therefore, visualizing data using Power BI allows the client to analyze data deeper and discover idle time and inefficiencies. This will help to create a better business strategy to optimize equipment utilization and find cost-saving opportunities. The main question we intended to answer in this analysis is:

> **Q:** *"Do all using equipment actually being utilized?"*

**What we did?**
* Developed a concept to optimize equipment performance by predicting renting time using Gradient Boosting and Neural Networks.
* Integrated data from three different files containing over 300,000 records into one and focused only on the overlapping periods.
* Created Power BI visualization dashboards for construction software to track & evaluate the utilization of 801 rental and owned
equipment at different construction sites, to identify inefficiently used equipment and idle periods.

> **SKILLS:** 

EDA, Data Cleaning, Data Transformation, Descriptive Analysis, Dashboard Reports, Data Visualization, Utilization Analysis, Recommendations  

> **TECHNOLOGY:**

**Power BI, Excel, Python**

![](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/docs/assets/XN_Project.png)

## [Market Basket Analysis for Online Retail Industry (Databricks)](https://github.com/fatishi/Market-Basket-Analysis-for-Online-Retail-Industry-by-Using-Databricks)

- **Code file:** [`Final Databricks_ALY6110_GroupEpsilon.pdf`](https://github.com/fatishi/Market-Basket-Analysis-for-Online-Retail-Industry-by-Using-Databricks/blob/main/Using%20Market%20Basket%20Analysis%20to%20Improve%20Product%20Bundle%20Sales%20Strategy%20for%20Online%20Retail%20companies.ipynb)
- **Project Report:** [`Final Report_ALY6110_GroupEpsilon.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Big%20Data%20Management/Final%20Report_ALY6110_GroupEpsilon.pdf)
- **Presentation Slides:** [`Final PPT_ALY6110_GroupEpsilon.pdf`](https://github.com/fatishi/Market-Basket-Analysis-for-Online-Retail-Industry-by-Using-Databricks/blob/main/Instructions%20of%20how%20to%20use%20Databricks%20and%20the%20insights%20from%20the%20analysis.pdf)

**Description:** 

A group project that I did with my teammates based on the data set from a UK-based online sales store. It contains records of more than 1 million transactions from January 12, 2009, to September 12, 2011. We created a Manual with instructions for doing data analysis, especially the Market Basket Analysis by using Apriori Algorithm for the retail industry. The purpose of this report is to help analysts who have no experience using the big data management tool ‚Äì Databricks understand how to use it to tackle real big data. The main question we intended to answer in this analysis is:

> *‚ÄúHow to create a better product bundle sales strategy for online retail companies by using Market Basket Analysis?‚Äù*. 

**What I did?**
* Conducted EDA and MBA with Apriori Algorithm using PySpark and SQL to study large transaction data with over 1 billion
records of UK-based online retail companies.
* Recommended better product bundle sales strategy to increase revenue based on insights of top-most sold product combinations.
* Created a Manual of 50 pages with step-by-step instructions for doing data analysis on Databricks.

**Skills:** Data Cleaning, EDA, Data Transformation, Visualization, Market Basket Analysis, Association Rule Learning

**Technology:** Excel, Apache Spark, Databricks: Apriori Algorithm, PySpark, SQL

![](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Big%20Data%20Management/images/MBA_ProductBundle.jpg)

## [Predicting Causes for Chicago Traffic Crashes (Classification)](https://github.com/fatishi/My_Portfolio/tree/main/Analytics%20System%20Technology)

- **Code file:** [`Final Python_ALY6140_group5.ipynb`](https://github.com/fatishi/My_Portfolio/blob/main/Analytics%20System%20Technology/Final%20Python_ALY6140_group5.ipynb)
- **Project Report:** [`Final Report_ALY6140_group5.pdf`](https://github.com/fatishi/My_Portfolio/blob/main/Analytics%20System%20Technology/Final%20Report_ALY6140_group5.pdf)
- **Presentation Slides:** [`Final PPT_ALY6140_group5.pdf`](https://github.com/fatishi/My_Portfolio/blob/main/Analytics%20System%20Technology/Final%20PPT_ALY6140_group5.pdf)

**Description:** A group project that I did with my teammate (Min-Chi Tsai) based on the real-data obtained from the Chicago Data Portal. The goal of the project is to help Chicago Police Department to predict the traffic crash type and understand the causes that lead to it. We are wondering if there are similar or common patterns that might help to predict the traffic crash. The main question we intended to answer in this analysis is *‚ÄúWhat factors affect the severity of the traffic crash type?‚Äù*. 
* Performed EDA and cleaning of data with 605,120 records as of May, 2022
* Pre-processed data: reducing feature cardinality, feature engineering, splitting, and scaling for ML models creation
* Built 3 ML models: logistic regression, random forest, and XGBoost to predict influential factors on traffic crashes in 2022

**Skills:** Data Cleaning, Data Analysis, Descriptive Statistics, Visualization, Writing Functions, Feature Engineering, Predictive Modeling, Classification  

**Technology:** Python: Pandas, Numpy, Matplotlib, Seaborn, Datetime, Sklearn, Statsmodels, Xgboost

![Models Comparison](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/docs/assets/Models_Comparison.png)

## [Bike Sharing Analysis - Tableau](https://github.com/fatishi/Fatima-s_Portfolio/tree/main/Data%20Visualization/Tableau/Bike%20Sharing%20Analysis)

- **Dashboards:** [`Tableau`](https://public.tableau.com/app/profile/yu.qiu7993/viz/BikeSharingAnalysis_16488700518180/Dashboard1)
- **Code file:** [`Final Tableau Dashb_ALY6070_Group 7.twbx`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Data%20Visualization/Tableau/Bike%20Sharing%20Analysis/Final%20Tableau%20Dashb_ALY6070_Group%207.twbx)
- **Project Report:** [`Final Report_ALY6070_Group 7.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Data%20Visualization/Tableau/Bike%20Sharing%20Analysis/Final%20Report_ALY6070_Group%207.pdf)
- **Presentation Slides:** [`Final PPT_ALY6070_Group 7.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Data%20Visualization/Tableau/Bike%20Sharing%20Analysis/Final%20PPT_ALY6070_Group%207.pdf)

**Description:** A group project that I did with my teammates based on the data set about the bike rental information collected mainly from Washington D.C in 2011 and 2012. This project aims to analyze the demand changes for bike-sharing by different periods and weather conditions as well as the different behavior patterns of the 2 user types - casual users and registered users. Based on the findings, we also provided suggestions to the bike-sharing company from a product and marketing manager perspective. Here we raised questions from 2 aspects that would help us understand the user behaviors of bike sharing:
1. *What are the time patterns of bike-sharing? Any difference between the 2 user types?*
2. *How do the weather conditions influence the number of bike rentals regarding specific user types?*

**Skills:** EDA, Descriptive Statistics, Visualization, Time-Series Analysis, Frequency Distribution

**Technology:** Tableau: Heatmap, Bar Chart, Line Chart, Time-Series

![](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Data%20Visualization/Tableau/Bike%20Sharing%20Analysis/images/Bike%20Sharing%20Analysis_Tableau%20Dashboards.jpg)


## [Predictive Analysis of Telco Customer Churn using ML Models - R](https://github.com/fatishi/Fatima-s_Portfolio/tree/main/Intermediate%20Analytics)

- **Code file:** [`Final R Script_ALY6015_Alpha.R`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Intermediate%20Analytics/Final%20R%20Script_ALY6015_Alpha.R)
- **Project Report:** [Final Report_ALY6015_Alpha.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Intermediate%20Analytics/Final%20Report_ALY6015_Alpha.pdf)
- **Presentation Slides:** [`Final PPT_ALY6015_Alpha.pdf`](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Intermediate%20Analytics/Final%20PPT_ALY6015_Alpha.pdf)

**Description:** A group project that I did with my teammates based on the data obtained from Kaggle. The goal of the project is to help Telecom Company to predict the churn rate of the telecom company, and understand the causes that lead to it. This is done by building 2 supervised machine learning models: Logistic Regression, and LASSO Regularization Regression. The main question we intended to answer in this analysis is *‚ÄúWhat are significant predictor variables that affect the Telco customers churn rate?‚Äù*. 
* Performed EDA, cleaning of data, and normalizing it for a more accurate analysis
* Pre-processed data: reducing feature cardinality, feature engineering, splitting, and preparing it for ML model creation
* Built 2 ML models: logistic regression, and LASSO Regularization Regression.

**Skills:** Data Cleaning, Data Analysis, Descriptive Statistics, Visualization, Writing Functions, Feature Engineering, Predictive Modeling, Classification  

**Technology:** R: caret, ggplot2, gridExtra, pROC, psych, dplyr, tidyverse 

![LR Model fitting on the Training Set](https://github.com/fatishi/Fatima-s_Portfolio/blob/main/Intermediate%20Analytics/LR%20model%20fitting%20on%20the%20Train%20Set.png)
